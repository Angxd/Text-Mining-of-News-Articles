{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from twitter_scrape_v1 import extract_by_user_v1\n",
    "from twitter_scrape_v2 import extract_by_user_v2\n",
    "from croma_scrape import extract_data_croma\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a10167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app = Flask(_name_)\n",
    "\n",
    "@app.route('/scrape/twitter/v1/<username>/<int:depth>', methods=['GET'])\n",
    "def twitter_scrape_v1(username, depth):\n",
    "    # Call your scraping function with username and depth\n",
    "\n",
    "    scraped_df = extract_by_user_v1(username, int(depth))\n",
    "    # Convert DataFrame to JSON\n",
    "    scraped_json = scraped_df.to_json(orient='records')\n",
    "    \n",
    "    return json.loads('{\"data\":['+scraped_json[1:-1]+']}')\n",
    "\n",
    "@app.route('/scrape/twitter/v2/<username>/<int:depth>', methods=['GET'])\n",
    "def twitter_scrape_v2(username, depth):\n",
    "    # Call your scraping function with username and depth\n",
    "\n",
    "    scraped_df = extract_by_user_v2(username, int(depth))\n",
    "    # Convert DataFrame to JSON\n",
    "    scraped_json = scraped_df.to_json(orient='records')\n",
    "    \n",
    "    return json.loads('{\"data\":['+scraped_json[1:-1]+']}')\n",
    "\n",
    "@app.route('/scrape/croma/<product>/<int:depth>', methods=['GET'])\n",
    "def croma_scrape(product, depth):\n",
    "    # Call your scraping function with product and depth\n",
    "\n",
    "    scraped_df = extract_data_croma(product, int(depth))\n",
    "    # Convert DataFrame to JSON\n",
    "    scraped_json = scraped_df.to_json(orient='records')\n",
    "    \n",
    "    return json.loads('{\"data\":['+scraped_json[1:-1]+']}')\n",
    "\n",
    "if _name_ == '_main_':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e15833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager as CM\n",
    "from selenium.webdriver.common.by import By\n",
    "from commons import (\n",
    "    save_string_to_file,\n",
    "    remove_string_section,\n",
    "    count_numbers_in_list,\n",
    "    break_strings_by_word,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Ad from tweets\n",
    "def process_lines(lines):\n",
    "    index_ad = -1\n",
    "    for i, line in enumerate(lines):\n",
    "        if line == \"Ad\":\n",
    "            index_ad = i\n",
    "            break\n",
    "\n",
    "    if index_ad != -1:\n",
    "        del lines[max(0, index_ad - 2):]\n",
    "    return lines\n",
    "\n",
    "\n",
    "def extract_by_user_v1(username=\"PizzaHutIN\", depth=10, return_type=\"excel\"):\n",
    "    # Set Chrome options and service to configure the browser\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    service = Service(executable_path=CM().install())\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    # Move to brand_profile\n",
    "    url_link = \"https://twitter.com/\" + username\n",
    "    driver.get(url_link)\n",
    "\n",
    "    # Access Login Option\n",
    "    login_option = driver.find_element(\n",
    "        By.XPATH, \"//div/div[1]/div/div/div/div[2]/div[2]/div/div/div[1]/a\"\n",
    "    )\n",
    "    login_option.click()\n",
    "\n",
    "    # Wait for 0.5 sec\n",
    "    time.sleep(8)\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    # Access Username Field\n",
    "    username_space = driver.find_element(\n",
    "        By.XPATH,\n",
    "        \"//div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div/div/div[5]/label/div/div[2]/div/input\",\n",
    "    )\n",
    "    # Entering Username\n",
    "    username_space.send_keys(\"mayankkuthar\")\n",
    "    # Clicking Next Button\n",
    "    next_button = driver.find_element(\n",
    "        By.XPATH,\n",
    "        \"//div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div/div/div[6]\",\n",
    "    )\n",
    "    next_button.click()\n",
    "\n",
    "    # Access Password Field\n",
    "    password_space = driver.find_element(\n",
    "        By.XPATH,\n",
    "        \"//div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[1]/div/div/div[3]/div/label/div/div[2]/div[1]/input\",\n",
    "    )\n",
    "    # Entering Password\n",
    "    password_space.send_keys(\"Mayank1887!\")\n",
    "    # Cliking login button\n",
    "    login_button = driver.find_element(\n",
    "        By.XPATH,\n",
    "        \"//div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div/div[1]/div/div/div\",\n",
    "    )\n",
    "    login_button.click()\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Pick Case Senesitive Username\n",
    "    usernames = driver.find_elements(\n",
    "        By.XPATH,\n",
    "        \"//div/div/div[2]/main/div/div/div/div[1]/div/div[3]/div/div/div/div/div[2]/div[1]/div/div[2]/div/div\",\n",
    "    )\n",
    "    for x in usernames:\n",
    "        username=x.text[1:]\n",
    "\n",
    "    current_tweet_list_path = (\n",
    "        \"//div/div/div[2]/main/div/div/div/div[1]/div/div[3]/div/div/section/div/div\"\n",
    "    )\n",
    "    twitts = []\n",
    "    for i in range(depth):\n",
    "        tweets = driver.find_elements(By.XPATH, current_tweet_list_path)\n",
    "        for tweet in tweets:\n",
    "            current_tweet = tweet.text.replace(\"Pinned\\n\", \"\")\n",
    "            twitts.append(current_tweet)\n",
    "        driver.execute_script(\"window.scrollBy(0,2000)\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    # Add username at the END of tweets\n",
    "    ext_user = driver.find_elements(\n",
    "        By.XPATH,\n",
    "        \"//div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[2]/div/div/div[1]\",\n",
    "    )\n",
    "    for x in ext_user:\n",
    "        twitts.append(x.text)\n",
    "\n",
    "    # Remove section Who to follow\n",
    "    tweet_string = remove_string_section(\"\\n\".join(twitts))\n",
    "\n",
    "    # Save the modified string to a text file\n",
    "    try:\n",
    "        save_string_to_file(\"checks\", \"tweet_string.txt\", tweet_string)\n",
    "    except:\n",
    "        print(\"An exception occurred in tweet_string.txt\")\n",
    "\n",
    "    # Break Into Individual Tweet\n",
    "    string_list = break_strings_by_word([tweet_string], \"@\" + username)\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    p_num=0\n",
    "    # Iterate over each tweet\n",
    "    for idx, string in enumerate(string_list):\n",
    "        lines = string.split(\"\\n\")\n",
    "        data = {}\n",
    "        if len(lines) > 4 and count_numbers_in_list(lines)%4 == 0:\n",
    "            #Removing Ad and and adding User-Name\n",
    "            if(\"Ad\" in lines):\n",
    "                lines = process_lines(lines)\n",
    "                for x in ext_user:\n",
    "                    lines.append(x.text)\n",
    "                    break\n",
    "\n",
    "            p_num+=1\n",
    "            data[\"Post.no\"] =  p_num\n",
    "            data[\"Name\"] = lines[-1]\n",
    "            data[\"Date\"] = lines[1]\n",
    "            data[\"Post\"] = \"\\n\".join(lines[2:-5])\n",
    "            data[\"Comments Count\"] = lines[-5]\n",
    "            data[\"Retweet Count\"] = lines[-4]\n",
    "            data[\"Likes\"] = lines[-3]\n",
    "            data[\"Views Count\"] = lines[-2]\n",
    "\n",
    "            # Append the extracted data to the list\n",
    "            data_list.append(data)\n",
    "\n",
    "        elif len(lines) > 4 and count_numbers_in_list(lines)%3 == 0:\n",
    "            #Removing Ad and and adding User-Name\n",
    "            if(\"Ad\" in lines):\n",
    "                lines = process_lines(lines)\n",
    "                for x in ext_user:\n",
    "                    lines.append(x.text)\n",
    "                    break\n",
    "\n",
    "            p_num+=1\n",
    "            data[\"Post.no\"] = p_num\n",
    "            data[\"Name\"] = lines[-1]\n",
    "            data[\"Date\"] = lines[1]\n",
    "            data[\"Post\"] = \"\\n\".join(lines[2:-4])\n",
    "            data[\"Comments Count\"] = lines[-4]\n",
    "            data[\"Retweet Count\"] = lines[-3]\n",
    "            data[\"Likes\"] = lines[-2]\n",
    "\n",
    "            # Append the extracted data to the list\n",
    "            data_list.append(data)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "    if(return_type == \"excel\"):\n",
    "        df.to_excel(\"Tweets_v1.xlsx\", index=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce18be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
